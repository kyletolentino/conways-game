2/10/2020
- 2x dense (32 neurons), concatenate, dense (16 neurons), dense (1 neuron)
    - loss= 0.0845, acc = 0.9785, val_loss = 0.0802, val_acc = 0.9802
    - nearly identical to original network (only differences in the hundredths place and beyond)
- 2x dense (64 neurons), concatenate, dense (64 neurons), dense (1 neuron)
    - loss: 0.0666 - acc: 0.9825 - val_loss: 0.0667 - val_acc: 0.9866
    - this it it chief


2/9/2020
- still trying CNN?
- will continue to fine tune MLP while trying to work out CNN
    - MLP just stays at 75% accuracy, but loss decreases while val_loss increases (overfitting?)
- its so weird, np.concatenate axes worked differently when pulling from data.pkl vs setting my matrices
- might have to change data so its 5x5 (that way we have a kernel of size 3x3?)
    - or keep 3x3 and do a 2x2 kernel
- "Error when checking model input: the list of Numpy arrays
    that you are passing to your model is not the size the model expected."
- Finally got MLP to work with shared layer (so I didn't have to concatenate matrices)
- I got it to work?
    - epoch size = 50
    - batch_size = 128
    - 2x dense layers (64 neurons), concatenate, dense layer (32 neurons), dense layer (1 neuron)
    - loss = 0.0674, acc = 0.9827, val_loss =0.0649, val_acc = 0.9823
    - too accurate? worried it might be looking at patterns too closely


2/8/2020
- need to figure out:
    - best architecture for NN
        - RNN/LSTM? dealing with sequential data
        - CNN? usually with images, but since there are two matrices, just stack em?
    - creating a virtualenv on EWS (can't use anaconda on these machines)
        - pandas
        - keras
        - TF 2.0
        - python 3.5.2 (only available python module on EWS that supports Keras and TF2.0-1)
        - seaborn
        - scikit-learn
    - how to create data
        - IDEA: create two/three functions that returns a tuple of matrices (start, done)
        - function1 will create correct matrices, function2/3 will create incorrect matrices
            - for incorrect, may do random and/or variation of function1, where I change few values
            - right now, will only create 1 real and 1 fake function
        - NOTE: I will assume a 3x3 grid size for keras challenge
        - aiming for even distribution of fake and real

    - working with dataframes (pandas) is a pain, will try to use numpy arrays instead (sigh)
        - would a list of [np array, np array, label] work?
    - epochs * steps per epoch = batch size (from my log.txt in disaster-tweets)

    - finally got model to work! (just simple MLP - will try to fine tune and then compare w/ CNN)


    

2/7/2020
- Setup git on Engineering Workstation (EWS)
- np.random.randit to generate 0s and 1s randomly
- need to figure out way to store previous state while iterating

- three cases: (1)Corners, (2)Sides/Edges, (3)Everything else
- Corners have 3 neighbors
- Sides/Edges have 5 neighbors
- Everything else has 8 neighbors (holds true for even x even matrices, par 2x2)

- 0x0, 1x1, 2x2 special cases (DONT FORGET)
- goal: move contents from game.py into another function (so I can call for x generations)
- need-to-do: figure out how to account for edges lol

- updated else check because I counted the 1 for the position we were looking at
- might need to just combine all functions into 1
    - provided that I put in conditions that prevent out of bounds (corner and edge)
    - might try continue if x,y go out of bounds (especially with -1,-1)
- got it to work!! (for most part)
    - (2,1) is 1 but should be 0
    - running func((2,1), state) returns a 0 but not on the board

- EUREEEKA!
    - I think it was the way I assigned ex[x,y] in game.py
    - Should have created copy first (with dim of first state)
    - then copy within for loops

- Now I need to:
    - test this for different dimensions
        - consider 0x0, 1x1, 2x2 cases
    - Create function to run this for x generations
        - pretty sure I have to use recursion
        - yea I have to lol (it works tho!)
    - Improve UI and arguments (argparse)

- [starting] Part 2 !! (in a bit b/c of argparse)


2/6/2020
- Initialized git for source control
- doing 2 for loops (x,y), might consider np.ndenumerate (read something about large dimensions)